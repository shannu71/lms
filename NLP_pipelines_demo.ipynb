{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EzcbwCXlD1j",
        "outputId": "d3188268-25da-4bc7-cecc-6038feb6102c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.8543396592140198, 'start': 97, 'end': 110, 'answer': 'Paris, France'}\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model = \"deepset/roberta-base-squad2\")\n",
        "\n",
        "context = \"\"\"The Eiffel Tower is one of the most famous landmarks in the world.\n",
        "It was constructed in 1889 in Paris, France, and stands at a height of 330 meters.\"\"\"\n",
        "\n",
        "question = \"Where is the Eiffel Tower located?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\",model = \"facebook/bart-large-cnn\")\n",
        "\n",
        "text = \"\"\"Artificial Intelligence (AI) is transforming industries by automating\n",
        "tasks, improving efficiency, and enabling data-driven decision-making.\n",
        "Companies across healthcare, finance, and transportation are integrating AI\n",
        "to enhance productivity and customer experiences.\"\"\"\n",
        "\n",
        "summary = summarizer(text, max_length=30, min_length=10, do_sample=False)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjUX0v23le8d",
        "outputId": "fb45e162-6b48-4131-a9d4-65f398842b3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': 'Companies across healthcare, finance, and transportation are integrating AI to enhance productivity and customer experiences. Artificial Intelligence (AI) is transforming industries by'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load table QA pipeline\n",
        "table_qa = pipeline(\"table-question-answering\", model = \"google/tapas-large-finetuned-wtq\")\n",
        "\n",
        "# Create a simple table\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\"],\n",
        "    \"Age\": [\"25\", \"30\"],\n",
        "    \"City\": [\"New York\", \"San Francisco\"]\n",
        "}\n",
        "table = pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Ask a question about the table\n",
        "question = \"Where does Bob live?\"\n",
        "result = table_qa(table=table, query=question)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSaeLirnlGfq",
        "outputId": "6254998b-ab95-4eb8-894c-a000544c1fa0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/tapas/tokenization_tapas.py:2699: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  text = normalize_for_match(row[col_index].text)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/tapas/tokenization_tapas.py:1493: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  cell = row[col_index]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': 'San Francisco', 'coordinates': [(1, 2)], 'cells': ['San Francisco'], 'aggregator': 'NONE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2text = pipeline(\"text2text-generation\", model = \"google/flan-t5-small\")\n",
        "\n",
        "text = \"Convert this sentence into a question: The sky is blue.\"\n",
        "result = text2text(text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcA1qHXuoh7V",
        "outputId": "88fcc30c-5e2d-43c4-f0dd-349f87af6609"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'The sky is blue.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"text-classification\",model = \"BAAI/bge-reranker-v2-m3\")\n",
        "\n",
        "text = \"I absolutely love this new AI model!\"\n",
        "result = classifier(text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMptGpiXoyTX",
        "outputId": "388962f3-9053-482a-e694-ff46c93e709e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.00037260729004628956}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\",model = \"openai-community/gpt2\")\n",
        "\n",
        "prompt = \"The future of AI is\"\n",
        "result = generator(prompt, max_length=30, num_return_sequences=1)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2qR0jWkr0C3",
        "outputId": "e6c18f27-e4fa-48d9-ef91-9f6bd51f78db"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'The future of AI is also under discussion, as Microsoft continues to innovate with the way we interact with devices, while the search engine will continue to evolve'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_pipeline = pipeline(\"token-classification\", grouped_entities=True, model = \"w11wo/indonesian-roberta-base-posp-tagger\")\n",
        "\n",
        "text = \"Elon Musk founded SpaceX in 2002 and acquired Twitter in 2022.\"\n",
        "result = ner_pipeline(text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRXBD1TgslRJ",
        "outputId": "72c4333b-ae40-48bc-e85b-c079da5d6b76"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'NNP', 'score': 0.96619684, 'word': ' El', 'start': 0, 'end': 2}, {'entity_group': 'NNP', 'score': 0.55945975, 'word': 'on', 'start': 2, 'end': 4}, {'entity_group': 'NNP', 'score': 0.9974427, 'word': ' Mus', 'start': 5, 'end': 8}, {'entity_group': 'NNP', 'score': 0.96648294, 'word': 'k', 'start': 8, 'end': 9}, {'entity_group': 'NNP', 'score': 0.9941748, 'word': ' found', 'start': 10, 'end': 15}, {'entity_group': 'NNP', 'score': 0.6980641, 'word': 'ed', 'start': 15, 'end': 17}, {'entity_group': 'NNP', 'score': 0.99584275, 'word': ' Space', 'start': 18, 'end': 23}, {'entity_group': 'NNP', 'score': 0.99600106, 'word': 'X', 'start': 23, 'end': 24}, {'entity_group': 'PPO', 'score': 0.9994222, 'word': ' in', 'start': 25, 'end': 27}, {'entity_group': 'NUM', 'score': 0.9998085, 'word': ' 2002', 'start': 28, 'end': 32}, {'entity_group': 'CCN', 'score': 0.9997335, 'word': ' and', 'start': 33, 'end': 36}, {'entity_group': 'NNP', 'score': 0.9730349, 'word': ' ac', 'start': 37, 'end': 39}, {'entity_group': 'NNP', 'score': 0.46778694, 'word': 'qu', 'start': 39, 'end': 41}, {'entity_group': 'NNP', 'score': 0.9635505, 'word': 'ired', 'start': 41, 'end': 45}, {'entity_group': 'NNP', 'score': 0.9988918, 'word': ' Twitter', 'start': 46, 'end': 53}, {'entity_group': 'PPO', 'score': 0.9994198, 'word': ' in', 'start': 54, 'end': 56}, {'entity_group': 'NUM', 'score': 0.9327776, 'word': ' 2022', 'start': 57, 'end': 61}, {'entity_group': 'SYM', 'score': 0.99653244, 'word': '.', 'start': 61, 'end': 62}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation_en_to_fr\", model = \"google-t5/t5-small\")\n",
        "\n",
        "text = \"Hello, how are you?\"\n",
        "result = translator(text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ0qFwO9uyXc",
        "outputId": "f56c9de8-a2ad-4f34-835b-a7cc5c1b0c08"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'translation_text': 'Bonjour, comment Ãªtes-vous ?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot = pipeline(\"zero-shot-classification\",model = \"facebook/bart-large-mnli\")\n",
        "\n",
        "text = \"I love playing football during the weekends.\"\n",
        "labels = [\"sports\", \"technology\", \"food\"]\n",
        "\n",
        "result = zero_shot(text, candidate_labels=labels)\n",
        "print(result['labels'])\n",
        "print(result['scores'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiDItKTgvA1z",
        "outputId": "d9e7fff0-0023-4167-af47-b49a7a3a3f48"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sports', 'technology', 'food']\n",
            "[0.9965085983276367, 0.0019449957180768251, 0.0015463430900126696]\n"
          ]
        }
      ]
    }
  ]
}